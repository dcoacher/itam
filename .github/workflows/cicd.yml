# CICD Process (contains multiple phases)
name: CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
  workflow_dispatch:

env:
  DOCKER_IMAGE: itam-app
  DOCKER_TAG: ${{ github.sha }}

jobs:
  # Phase 1: Test
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flask==3.0.0 pytest==8.2.1

      - name: Run tests
        run: |
          pytest .github/workflows/tests/ -v --tb=short

  # Phase 2: Build Docker Image
  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile
          push: ${{ github.event_name != 'pull_request' }}
          tags: |
            ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}
            ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:latest
          cache-from: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:buildcache
          cache-to: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:buildcache,mode=max

  # Phase 3: Deploy to Kubernetes
  deploy:
    name: Deploy to Kubernetes
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name != 'pull_request' && github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'

      - name: Set up kubeconfig for self-managed Kubernetes
        run: |
          mkdir -p ~/.kube
          # Decode base64 and write to config file
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > ~/.kube/config || {
            echo "ERROR: Failed to decode KUBECONFIG secret"
            echo "Please verify the secret is properly base64 encoded"
            exit 1
          }
          chmod 600 ~/.kube/config
          # Verify the config file is valid YAML
          if ! kubectl --kubeconfig ~/.kube/config config view &>/dev/null; then
            echo "ERROR: Invalid kubeconfig format"
            echo "First few lines of decoded config:"
            head -5 ~/.kube/config || true
            exit 1
          fi
          # Show current server URL before replacement
          echo "Current kubeconfig server:"
          kubectl --kubeconfig ~/.kube/config config view --minify -o jsonpath='{.clusters[0].cluster.server}' || true
          echo ""
          # Replace private IP (10.0.1.10) with public IP
          PUBLIC_IP="${{ secrets.KUBERNETES_PUBLIC_IP }}"
          if [ -z "$PUBLIC_IP" ]; then
            echo "WARNING: KUBERNETES_PUBLIC_IP secret not set"
            echo "Trying to extract from kubeconfig or use default..."
            # Try to get public IP from Terraform output or use a placeholder
            PUBLIC_IP="REPLACE_WITH_PUBLIC_IP"
          fi
          if [ "$PUBLIC_IP" != "REPLACE_WITH_PUBLIC_IP" ]; then
            echo "Updating kubeconfig to use public IP: $PUBLIC_IP"
            # Replace all variations of private IP
            sed -i "s|10.0.1.10:6443|$PUBLIC_IP:6443|g" ~/.kube/config
            sed -i "s|https://10.0.1.10:6443|https://$PUBLIC_IP:6443|g" ~/.kube/config
            sed -i "s|server: https://10.0.1.10:6443|server: https://$PUBLIC_IP:6443|g" ~/.kube/config
            # Disable certificate verification for public IP access
            # (Certificate is only valid for private IP 10.0.1.10)
            echo "Disabling certificate verification for public IP access..."
            kubectl --kubeconfig ~/.kube/config config set-cluster kubernetes --insecure-skip-tls-verify=true
            # Verify replacement
            echo "Updated kubeconfig server:"
            kubectl --kubeconfig ~/.kube/config config view --minify -o jsonpath='{.clusters[0].cluster.server}' || true
            echo ""
          else
            echo "ERROR: KUBERNETES_PUBLIC_IP secret must be set"
            echo "Please add KUBERNETES_PUBLIC_IP secret with your control plane public IP"
            exit 1
          fi

      - name: Verify Kubernetes connection
        run: |
          kubectl cluster-info
          kubectl get nodes

      - name: Deploy NFS PersistentVolume
        run: |
          # Apply NFS PV (if not exists, create from control plane)
          # You can also copy nfs-pv.yaml from control plane to repo
          kubectl apply -f - <<EOF || true
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: itam-nfs-pv
            labels:
              type: nfs
          spec:
            capacity:
              storage: 10Gi
            accessModes:
              - ReadWriteMany
            persistentVolumeReclaimPolicy: Retain
            storageClassName: nfs-client
            nfs:
              path: /srv/nfs/k8s
              server: 10.0.1.10
            mountOptions:
              - soft
              - timeo=30
              - retrans=3
              - nfsvers=4.1
          ---
          apiVersion: storage.k8s.io/v1
          kind: StorageClass
          metadata:
            name: nfs-client
          provisioner: kubernetes.io/no-provisioner
          volumeBindingMode: Immediate
          EOF

      - name: Deploy application
        run: |
          # Check if deployment exists
          if kubectl get deployment itam-app -n default &>/dev/null; then
            echo "Deployment exists. Updating image..."
            kubectl set image deployment/itam-app \
              itam-app=${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }} \
              -n default
            kubectl rollout status deployment/itam-app -n default --timeout=5m
          else
            echo "Deployment not found. Creating new deployment..."
            # Create PVC
            cat <<'PVCEOF' | kubectl apply -f -
            apiVersion: v1
            kind: PersistentVolumeClaim
            metadata:
              name: itam-app-pvc
              labels:
                app: itam-app
            spec:
              accessModes:
                - ReadWriteMany
              storageClassName: nfs-client
              resources:
                requests:
                  storage: 1Gi
            PVCEOF
            # Create Deployment
            cat <<DEPLOYEOF | kubectl apply -f -
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: itam-app
              labels:
                app: itam-app
            spec:
              replicas: 2
              selector:
                matchLabels:
                  app: itam-app
              template:
                metadata:
                  labels:
                    app: itam-app
                spec:
                  tolerations:
                  - key: node-role.kubernetes.io/control-plane
                    operator: Exists
                    effect: NoSchedule
                  - key: node-role.kubernetes.io/master
                    operator: Exists
                    effect: NoSchedule
                  containers:
                  - name: itam-app
                    image: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}
                    imagePullPolicy: Always
                    ports:
                    - containerPort: 31415
                      name: http
                    env:
                    - name: ITAM_DATA_DIR
                      value: /app/dummy-data
                    - name: PORT
                      value: "31415"
                    - name: FLASK_DEBUG
                      value: "False"
                    volumeMounts:
                    - name: data
                      mountPath: /app/dummy-data
                    resources:
                      requests:
                        memory: "128Mi"
                        cpu: "100m"
                      limits:
                        memory: "256Mi"
                        cpu: "200m"
                  volumes:
                  - name: data
                    persistentVolumeClaim:
                      claimName: itam-app-pvc
            DEPLOYEOF
            # Create Service
            cat <<'SVCEOF' | kubectl apply -f -
            apiVersion: v1
            kind: Service
            metadata:
              name: itam-app
              labels:
                app: itam-app
            spec:
              type: NodePort
              ports:
              - port: 31415
                targetPort: http
                protocol: TCP
                name: http
                nodePort: 31415
              selector:
                app: itam-app
            SVCEOF
            # Wait for deployment to be ready
            echo "Waiting for deployment to be ready..."
            kubectl wait --for=condition=available deployment/itam-app -n default --timeout=5m || true
          fi

      - name: Verify deployment
        run: |
          echo "=== Deployment Status ==="
          kubectl get pods -l app=itam-app
          kubectl get svc itam-app
          echo ""
          echo "âœ“ Deployment completed"
          echo "Image deployed: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}"

